
#######################
# Regression analysis #
#######################


# 1 linear regression 

import statsmodels.api as sm
from sklearn.metrics import mean_squared_error


X = df4.drop('died', axis = 1)
y = df4['died']


model1 = sm.OLS(y, X)
results = model1.fit()

sm.Logit()
print(results.summary())

# very strong impact factors, exepct for:
#tobacco, renal_chronic, other_disease, 

# LogReg

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report

model2 = sm.Logit(y, X)
results = model2.fit()

print(results.summary())

# very strong impact factors, exepct for:
#tobacco, renal_chronic, obesity, other_disease, hypertension

ll = ['tobacco', 'renal_chronic', 'obesity', 'other_disease', 'hypertension' ]

df_small = df4

for a in ll:
    del df_small[a]
    
## DF to be used
df_small.to_csv(r'C:\Users\Nico\Documents\Data\covid_df_small.csv')
df_small = pd.read_csv(r'C:\Users\Nico\Documents\Data\covid_df_small.csv')
df4 = pd.read_csv(r'C:\Users\Nico\Documents\Data\covid_df4.csv')
##

#normal X,y
X = df4.drop('died', axis = 1)
y = df4['died']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=30)

#smaller X,y
X_s = df_small.drop('died', axis = 1)
y_s = df_small['died']

X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_s, y_s, test_size=0.3, random_state=30)

## performing PCA
from sklearn.decomposition import PCA

pca = PCA(n_components=8)


df5 = df4.drop('died', axis = 1)

pc = pca.fit_transform(df5)

df_p1 = pd.DataFrame(data = pc
             , columns = ['p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8'])


df_p = df_p1.merge(df4['died'], left_index=True, right_index=True)


df_p.to_csv(r'C:\Users\Nico\Documents\Data\covid_df_p.csv')
df_p = pd.read_csv(r'C:\Users\Nico\Documents\Data\covid_df_p.csv')

del df_p['Unnamed: 0']

# PCA normalizing

df_to_be_stand = df_p[['p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']]


df_not_to_be_stand = pd.DataFrame(df_p['died'])

## actually normalize
from sklearn import preprocessing

def norm(df):
    dataN = ( (df - df.min() ) / (df.max() - df.min() ) )
    return dataN

p11 = ( (df_to_be_stand['p1'] - df_to_be_stand['p1'].min() )/ ( df_to_be_stand['p1'].max() - df_to_be_stand['p1'].min() ) )
p12 = ( (df_to_be_stand['p2'] - df_to_be_stand['p2'].min() )/ ( df_to_be_stand['p2'].max() - df_to_be_stand['p2'].min() ) )
p13 = ( (df_to_be_stand['p3'] - df_to_be_stand['p3'].min() )/ ( df_to_be_stand['p3'].max() - df_to_be_stand['p3'].min() ) )
p14 = ( (df_to_be_stand['p4'] - df_to_be_stand['p4'].min() )/ ( df_to_be_stand['p4'].max() - df_to_be_stand['p4'].min() ) )
p15 = ( (df_to_be_stand['p5'] - df_to_be_stand['p5'].min() )/ ( df_to_be_stand['p5'].max() - df_to_be_stand['p5'].min() ) )
p16 = ( (df_to_be_stand['p6'] - df_to_be_stand['p6'].min() )/ ( df_to_be_stand['p6'].max() - df_to_be_stand['p6'].min() ) )
p17 = ( (df_to_be_stand['p7'] - df_to_be_stand['p7'].min() )/ ( df_to_be_stand['p7'].max() - df_to_be_stand['p7'].min() ) )
p18 = ( (df_to_be_stand['p8'] - df_to_be_stand['p8'].min() )/ ( df_to_be_stand['p8'].max() - df_to_be_stand['p8'].min() ) )


p11 = pd.DataFrame(p11)
p11['p12'] = p12
p11['p13'] = p13
p11['p14'] = p14
p11['p15'] = p15
p11['p16'] = p16
p11['p17'] = p17
p11['p18'] = p18



# putting them together

df_pca = df_not_to_be_stand.merge(p11, left_index=True, right_index=True)


df_pca.to_csv(r'C:\Users\Nico\Documents\Data\covid_df_pca.csv')
df_pca = pd.read_csv(r'C:\Users\Nico\Documents\Data\covid_df_pca.csv')

##
del df_pca['Unnamed: 0']


X_p = np.array(df_pca.drop('died', axis = 1))
y_p = df_pca['died'].values


X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_p, y_p, test_size=0.3, random_state=30)








